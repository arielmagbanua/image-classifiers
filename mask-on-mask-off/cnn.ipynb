{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "notebook_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1dcTH6lEp0DZgYsZTfoCx39yuhHLBC7WJ",
      "authorship_tag": "ABX9TyMGV8Nrm9GCj/8hKkb1Xxgz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arielmagbanua/image-classifiers/blob/main/mask-on-mask-off/cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3N7yKBPmUjp"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "import os\r\n",
        "import zipfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04MxepmksJ62"
      },
      "source": [
        "# Extract and Prepare Dataset\r\n",
        "\r\n",
        "1.) Mount your Google Drive\r\n",
        "\r\n",
        "2.) Designate a directory where you want to extract your dataset (E.g. `/content/mask-on-mask-off`).\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gB_YzUbsn2g3"
      },
      "source": [
        "# The path where to extract the dataset\r\n",
        "COLAB_DATA_SET_PATH = '/content/mask-on-mask-off'\r\n",
        "\r\n",
        "# clean up directory\r\n",
        "!rm -R $COLAB_DATA_SET_PATH\r\n",
        "\r\n",
        "data_zip = '/content/drive/MyDrive/mlds/dataset/mask_on_off.zip'\r\n",
        "zip_ref = zipfile.ZipFile(data_zip, 'r')\r\n",
        "zip_ref.extractall(COLAB_DATA_SET_PATH)\r\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqg7EQxntaFQ"
      },
      "source": [
        "# Constants / Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udMp5s6NtkK9",
        "outputId": "17727f86-43af-4ef4-a155-61b6c9f0164a"
      },
      "source": [
        "DESIRED_ACCURACY = 0.999\r\n",
        "\r\n",
        "dataset_path = os.path.join(COLAB_DATA_SET_PATH)\r\n",
        "print(dataset_path)\r\n",
        "\r\n",
        "IMAGE_WIDTH = 320\r\n",
        "IMAGE_HEIGHT = 320"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/mask-on-mask-off\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JF7gzF0Et7aI"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM1tuWwZt87r"
      },
      "source": [
        "class Callbacks(tf.keras.callbacks.Callback):\r\n",
        "  def on_epoch_end(self, epoch, logs={}):\r\n",
        "    if logs.get('accuracy') > DESIRED_ACCURACY:\r\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\r\n",
        "      self.model.stop_training = True\r\n",
        "\r\n",
        "# create the callbacks\r\n",
        "callbacks = Callbacks()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tdH8oL3uQiS"
      },
      "source": [
        "# Build the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyIXuQ0WuSer",
        "outputId": "0b3daeb5-4572-4d10-eccd-7ff6db65abce"
      },
      "source": [
        "model = tf.keras.models.Sequential([\r\n",
        "  # input layer\r\n",
        "  # first convolution\r\n",
        "  tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3)),\r\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "\r\n",
        "  # second convolution\r\n",
        "  tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\r\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "\r\n",
        "  # third convolution\r\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\r\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "\r\n",
        "  # fourth convolution\r\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\r\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "\r\n",
        "  # fifth convolution\r\n",
        "  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\r\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\r\n",
        "\r\n",
        "  # Flatten the results to feed into a DNN\r\n",
        "  tf.keras.layers.Flatten(),\r\n",
        "\r\n",
        "  # 512 neuron hidden layer\r\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\r\n",
        "\r\n",
        "  # Only 1 output neuron.\r\n",
        "  # It will contain a value from 0-1 where 0 for 1 class ('mask on') and 1 for the other ('mask off')\r\n",
        "  tf.keras.layers.Dense(1, activation='sigmoid')\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_143 (Conv2D)          (None, 318, 318, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_143 (MaxPoolin (None, 159, 159, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_144 (Conv2D)          (None, 157, 157, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_144 (MaxPoolin (None, 78, 78, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_145 (Conv2D)          (None, 76, 76, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_145 (MaxPoolin (None, 38, 38, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_146 (Conv2D)          (None, 36, 36, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_146 (MaxPoolin (None, 18, 18, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_147 (Conv2D)          (None, 16, 16, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_147 (MaxPoolin (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_30 (Flatten)         (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 512)               2097664   \n",
            "_________________________________________________________________\n",
            "dense_67 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 2,195,617\n",
            "Trainable params: 2,195,617\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtAnPnKWyHRS"
      },
      "source": [
        "# Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnxHmaFyyJ-w"
      },
      "source": [
        "model.compile(\r\n",
        "  loss='binary_crossentropy',\r\n",
        "  optimizer=Adam(),\r\n",
        "  metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lB5ujwecubmt"
      },
      "source": [
        "# Prepare Dataset with Data Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s62eGLSyuguz",
        "outputId": "657a4364-cb30-48e0-9046-ba502e7d30c6"
      },
      "source": [
        "# All images will be rescaled by 1./255\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "  rescale=1./255,\r\n",
        "  shear_range=0.2,\r\n",
        "  zoom_range=0.2,\r\n",
        "  height_shift_range=0.2,\r\n",
        "  rotation_range=35,\r\n",
        "  brightness_range=[0.2, 1.0],\r\n",
        "  horizontal_flip=True,\r\n",
        "  validation_split=0.2\r\n",
        ")\r\n",
        "\r\n",
        "# training data generator\r\n",
        "train_generator = train_datagen.flow_from_directory(\r\n",
        "  dataset_path,  # This is the source directory for training images\r\n",
        "  target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),  # All images will be resized to 360x360\r\n",
        "  batch_size=128,\r\n",
        "  class_mode='binary',\r\n",
        "  seed=7,\r\n",
        "  subset='training'\r\n",
        ")\r\n",
        "\r\n",
        "# validation data generator\r\n",
        "validation_generator = train_datagen.flow_from_directory(\r\n",
        "  dataset_path,\r\n",
        "  target_size=(IMAGE_WIDTH, IMAGE_HEIGHT),  # All images will be resized to 360x360\r\n",
        "  batch_size=32,\r\n",
        "  class_mode='binary',\r\n",
        "  seed=7,\r\n",
        "  subset='validation'\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2870 images belonging to 2 classes.\n",
            "Found 717 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDL8fhjYxlFm"
      },
      "source": [
        "# Train / Fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRGu0j0_viCN",
        "outputId": "92df65bf-da4f-422c-e42b-21af039608d9"
      },
      "source": [
        "history = model.fit(\r\n",
        "  train_generator,\r\n",
        "  validation_data=validation_generator,\r\n",
        "  steps_per_epoch=8,\r\n",
        "  epochs=100,\r\n",
        "  verbose=1,\r\n",
        "  # callbacks=[callbacks]\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.6965 - accuracy: 0.5600 - val_loss: 0.6739 - val_accuracy: 0.5007\n",
            "Epoch 2/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.6427 - accuracy: 0.6209 - val_loss: 0.4272 - val_accuracy: 0.8494\n",
            "Epoch 3/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.4727 - accuracy: 0.7801 - val_loss: 0.2821 - val_accuracy: 0.8940\n",
            "Epoch 4/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.2631 - accuracy: 0.8951 - val_loss: 0.4935 - val_accuracy: 0.8061\n",
            "Epoch 5/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.2300 - accuracy: 0.9206 - val_loss: 0.1944 - val_accuracy: 0.9344\n",
            "Epoch 6/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.1637 - accuracy: 0.9460 - val_loss: 0.1560 - val_accuracy: 0.9372\n",
            "Epoch 7/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.1248 - accuracy: 0.9556 - val_loss: 0.6728 - val_accuracy: 0.7252\n",
            "Epoch 8/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.2257 - accuracy: 0.9374 - val_loss: 0.1988 - val_accuracy: 0.9317\n",
            "Epoch 9/100\n",
            "8/8 [==============================] - 53s 7s/step - loss: 0.1406 - accuracy: 0.9623 - val_loss: 0.3276 - val_accuracy: 0.8926\n",
            "Epoch 10/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.1119 - accuracy: 0.9636 - val_loss: 0.1951 - val_accuracy: 0.9358\n",
            "Epoch 11/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0981 - accuracy: 0.9520 - val_loss: 0.2164 - val_accuracy: 0.9219\n",
            "Epoch 12/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.1109 - accuracy: 0.9643 - val_loss: 0.4113 - val_accuracy: 0.8759\n",
            "Epoch 13/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0604 - accuracy: 0.9768 - val_loss: 0.0997 - val_accuracy: 0.9735\n",
            "Epoch 14/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0724 - accuracy: 0.9754 - val_loss: 0.0919 - val_accuracy: 0.9651\n",
            "Epoch 15/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.1039 - accuracy: 0.9681 - val_loss: 0.1175 - val_accuracy: 0.9679\n",
            "Epoch 16/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0793 - accuracy: 0.9684 - val_loss: 0.2772 - val_accuracy: 0.9149\n",
            "Epoch 17/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0798 - accuracy: 0.9759 - val_loss: 0.1271 - val_accuracy: 0.9623\n",
            "Epoch 18/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0717 - accuracy: 0.9786 - val_loss: 0.2291 - val_accuracy: 0.9247\n",
            "Epoch 19/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0557 - accuracy: 0.9769 - val_loss: 0.2501 - val_accuracy: 0.9191\n",
            "Epoch 20/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0734 - accuracy: 0.9784 - val_loss: 0.1187 - val_accuracy: 0.9554\n",
            "Epoch 21/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0397 - accuracy: 0.9889 - val_loss: 0.1079 - val_accuracy: 0.9623\n",
            "Epoch 22/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0452 - accuracy: 0.9846 - val_loss: 0.1172 - val_accuracy: 0.9609\n",
            "Epoch 23/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.1878 - val_accuracy: 0.9400\n",
            "Epoch 24/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0603 - accuracy: 0.9877 - val_loss: 0.1482 - val_accuracy: 0.9568\n",
            "Epoch 25/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.1987 - accuracy: 0.9343 - val_loss: 0.8017 - val_accuracy: 0.7252\n",
            "Epoch 26/100\n",
            "8/8 [==============================] - 53s 7s/step - loss: 0.1740 - accuracy: 0.9312 - val_loss: 0.2160 - val_accuracy: 0.9066\n",
            "Epoch 27/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.1701 - accuracy: 0.9349 - val_loss: 0.1852 - val_accuracy: 0.9247\n",
            "Epoch 28/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.1244 - accuracy: 0.9509 - val_loss: 0.1684 - val_accuracy: 0.9247\n",
            "Epoch 29/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0742 - accuracy: 0.9725 - val_loss: 0.1201 - val_accuracy: 0.9526\n",
            "Epoch 30/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0476 - accuracy: 0.9876 - val_loss: 0.1183 - val_accuracy: 0.9554\n",
            "Epoch 31/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0409 - accuracy: 0.9900 - val_loss: 0.1288 - val_accuracy: 0.9596\n",
            "Epoch 32/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0482 - accuracy: 0.9869 - val_loss: 0.0493 - val_accuracy: 0.9847\n",
            "Epoch 33/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0212 - accuracy: 0.9929 - val_loss: 0.1160 - val_accuracy: 0.9609\n",
            "Epoch 34/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0148 - accuracy: 0.9982 - val_loss: 0.2145 - val_accuracy: 0.9386\n",
            "Epoch 35/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0552 - accuracy: 0.9827 - val_loss: 0.1259 - val_accuracy: 0.9637\n",
            "Epoch 36/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0965 - accuracy: 0.9699 - val_loss: 0.0344 - val_accuracy: 0.9916\n",
            "Epoch 37/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0590 - accuracy: 0.9818 - val_loss: 0.1907 - val_accuracy: 0.9303\n",
            "Epoch 38/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0439 - accuracy: 0.9856 - val_loss: 0.2274 - val_accuracy: 0.9275\n",
            "Epoch 39/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0587 - accuracy: 0.9863 - val_loss: 0.1172 - val_accuracy: 0.9623\n",
            "Epoch 40/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0281 - accuracy: 0.9950 - val_loss: 0.1348 - val_accuracy: 0.9596\n",
            "Epoch 41/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0305 - accuracy: 0.9922 - val_loss: 0.0960 - val_accuracy: 0.9637\n",
            "Epoch 42/100\n",
            "8/8 [==============================] - 53s 7s/step - loss: 0.0401 - accuracy: 0.9815 - val_loss: 0.1229 - val_accuracy: 0.9596\n",
            "Epoch 43/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0218 - accuracy: 0.9939 - val_loss: 0.1620 - val_accuracy: 0.9596\n",
            "Epoch 44/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0138 - accuracy: 0.9956 - val_loss: 0.1449 - val_accuracy: 0.9582\n",
            "Epoch 45/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0198 - accuracy: 0.9945 - val_loss: 0.1630 - val_accuracy: 0.9582\n",
            "Epoch 46/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0197 - accuracy: 0.9930 - val_loss: 0.0276 - val_accuracy: 0.9902\n",
            "Epoch 47/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0352 - accuracy: 0.9876 - val_loss: 0.1724 - val_accuracy: 0.9526\n",
            "Epoch 48/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0365 - accuracy: 0.9858 - val_loss: 0.1881 - val_accuracy: 0.9498\n",
            "Epoch 49/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0601 - accuracy: 0.9781 - val_loss: 0.1600 - val_accuracy: 0.9400\n",
            "Epoch 50/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 0.0319 - val_accuracy: 0.9916\n",
            "Epoch 51/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0482 - accuracy: 0.9819 - val_loss: 0.0759 - val_accuracy: 0.9749\n",
            "Epoch 52/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0224 - accuracy: 0.9930 - val_loss: 0.1088 - val_accuracy: 0.9637\n",
            "Epoch 53/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0132 - accuracy: 0.9952 - val_loss: 0.0377 - val_accuracy: 0.9847\n",
            "Epoch 54/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0112 - accuracy: 0.9973 - val_loss: 0.0403 - val_accuracy: 0.9916\n",
            "Epoch 55/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0336 - accuracy: 0.9866 - val_loss: 0.0861 - val_accuracy: 0.9735\n",
            "Epoch 56/100\n",
            "8/8 [==============================] - 55s 7s/step - loss: 0.0321 - accuracy: 0.9877 - val_loss: 0.0834 - val_accuracy: 0.9777\n",
            "Epoch 57/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0212 - accuracy: 0.9922 - val_loss: 0.0588 - val_accuracy: 0.9791\n",
            "Epoch 58/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0142 - accuracy: 0.9964 - val_loss: 0.0685 - val_accuracy: 0.9833\n",
            "Epoch 59/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0179 - accuracy: 0.9927 - val_loss: 0.0794 - val_accuracy: 0.9791\n",
            "Epoch 60/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0258 - accuracy: 0.9953 - val_loss: 0.0844 - val_accuracy: 0.9777\n",
            "Epoch 61/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0373 - accuracy: 0.9856 - val_loss: 0.1097 - val_accuracy: 0.9707\n",
            "Epoch 62/100\n",
            "8/8 [==============================] - 52s 7s/step - loss: 0.0211 - accuracy: 0.9928 - val_loss: 0.1455 - val_accuracy: 0.9554\n",
            "Epoch 63/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0244 - accuracy: 0.9920 - val_loss: 0.0523 - val_accuracy: 0.9805\n",
            "Epoch 64/100\n",
            "8/8 [==============================] - 54s 7s/step - loss: 0.0153 - accuracy: 0.9950 - val_loss: 0.1263 - val_accuracy: 0.9637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gemufTZRBIh"
      },
      "source": [
        "# Plot the Training History"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYhl5xocRI6M"
      },
      "source": [
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "\r\n",
        "epochs = range(len(acc))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "\r\n",
        "plt.figure()\r\n",
        "\r\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\r\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\r\n",
        "plt.title('Training and validation loss')\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BdDxRxFI-Zb"
      },
      "source": [
        "#Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdEzopvyJBrk"
      },
      "source": [
        "import pathlib\r\n",
        "import PIL\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "COLAB_EVAL_DATASET_PATH = '/content/drive/MyDrive/mlds/dataset/evaluation_data_set'\r\n",
        "\r\n",
        "eval_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "  COLAB_EVAL_DATASET_PATH,\r\n",
        "  seed=123,\r\n",
        "  image_size=(IMAGE_WIDTH, IMAGE_HEIGHT)\r\n",
        ")\r\n",
        "\r\n",
        "class_names = eval_ds.class_names\r\n",
        "# print(class_names)\r\n",
        "\r\n",
        "# plt.figure(figsize=(10, 10))\r\n",
        "\r\n",
        "# for images, labels in eval_ds.take(1):\r\n",
        "#   print('yo')\r\n",
        "#   for i in range(10):\r\n",
        "#     ax = plt.subplot(4, 4, i + 1)\r\n",
        "\r\n",
        "#     image = images[i].numpy().astype(\"uint8\")\r\n",
        "#     plt.imshow(image)\r\n",
        "#     plt.title(class_names[labels[i]])\r\n",
        "#     plt.axis(\"off\")\r\n",
        "\r\n",
        "def infer(class_names, model, x):\r\n",
        "  \r\n",
        "  prediction = model.predict(x)\r\n",
        "  result_index = np.argmax(prediction)\r\n",
        "  probability = prediction[0][result_index]\r\n",
        "  prediction_class_index = round(probability)\r\n",
        "\r\n",
        "  return probability, class_names[prediction_class_index]\r\n",
        "\r\n",
        "data_dir = pathlib.Path(COLAB_EVAL_DATASET_PATH)\r\n",
        "\r\n",
        "plt.figure(figsize=(10, 10))\r\n",
        "\r\n",
        "# mask on inference example\r\n",
        "image_paths = list(data_dir.glob('mask_on/*.jpg'))\r\n",
        "image = tf.keras.preprocessing.image.load_img(image_paths[0])\r\n",
        "image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\r\n",
        "image = tf.keras.preprocessing.image.img_to_array(image)\r\n",
        "plt.subplot(2, 2, 1)\r\n",
        "plt.imshow(image.astype(\"uint8\"))\r\n",
        "\r\n",
        "image_input = tf.expand_dims(image, axis=0)\r\n",
        "pci, class_name = infer(class_names, model, image_input)\r\n",
        "plt.title('{} = {}'.format(pci, class_name))\r\n",
        "\r\n",
        "\r\n",
        "# mask off inference example\r\n",
        "image_paths = list(data_dir.glob('mask_off/*.jpg'))\r\n",
        "image = tf.keras.preprocessing.image.load_img(image_paths[4])\r\n",
        "image = image.resize((IMAGE_WIDTH, IMAGE_HEIGHT))\r\n",
        "image = tf.keras.preprocessing.image.img_to_array(image)\r\n",
        "\r\n",
        "plt.subplot(2, 2, 2)\r\n",
        "plt.imshow(image.astype(\"uint8\"))\r\n",
        "\r\n",
        "image_input = tf.expand_dims(image, axis=0)\r\n",
        "pci, class_name = infer(class_names, model, image_input)\r\n",
        "plt.title('{} = {}'.format(pci, class_name))\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et2Md5VtCKqT"
      },
      "source": [
        "# Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jnjxof6xCMuK"
      },
      "source": [
        "models_dir_path = COLAB_DATA_SET_PATH + '/models'\r\n",
        "model_path = models_dir_path + '/moo.h5'\r\n",
        "\r\n",
        "model.save(model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNA4XA7nQ8Tg"
      },
      "source": [
        "# Convert the Model to Javascript"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0LVTfqQRAHf"
      },
      "source": [
        "!pip install tensorflowjs\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "!tensorflowjs_converter --input_format keras $model_path $models_dir_path\r\n",
        "\r\n",
        "zip_path = COLAB_DATA_SET_PATH + '/moo_models.zip'\r\n",
        "\r\n",
        "!zip -r $COLAB_DATA_SET_PATH $models_dir_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGF2ginnUogM"
      },
      "source": [
        "  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}